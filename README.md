üöÄ AI Document Analyst (RAG)
Un chatbot IA full-stack qui r√©pond de mani√®re intelligente et contextuelle √† des questions complexes sur vos documents priv√©s.

üìú Aper√ßu
Ce projet est un chatbot IA full-stack qui va au-del√† d'une simple conversation. Gr√¢ce √† un pipeline de Retrieval-Augmented Generation (RAG), il permet √† l'API Gemini Pro de Google d'analyser en profondeur le contenu de documents fournis par l'utilisateur (.pdf, .docx, .txt) et de fournir des r√©ponses pr√©cises et sourc√©es.

‚ú® Fonctionnalit√©s Cl√©s
Upload Multi-fichiers : Accepte plusieurs documents de formats vari√©s (PDF, DOCX, TXT).

Traitement de Texte Intelligent : Divise les documents en "chunks" optimis√©s pour le traitement par le LLM.

Base de Donn√©es Vectorielle : Cr√©e des embeddings des chunks de texte et les stocke pour une recherche s√©mantique rapide.

Pipeline RAG : Pour chaque question, le syst√®me retrouve les passages les plus pertinents dans les documents et les fournit au LLM comme contexte, garantissant des r√©ponses factuelles et pr√©cises.

Interface Utilisateur Interactive : Une interface simple et intuitive construite avec Streamlit.

üõ†Ô∏è Architecture et Stack Technique
Application : Python, Streamlit

IA / ML : Google Gemini Pro, LangChain (pour le pipeline RAG), Sentence Transformers (pour les embeddings)

Base de Donn√©es Vectorielle : FAISS (ou ChromaDB)

D√©ploiement : Streamlit Community Cloud, Git, GitHub

‚öôÔ∏è Installation et Lancement
Pour lancer ce projet localement, suivez ces √©tapes :

Clonez le repository :

Bash

git clone https://github.com/yahias29/ai-chatbot.git
cd ai-chatbot
Cr√©ez un environnement virtuel et installez les d√©pendances :

Bash

python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
Configurez les variables d'environnement :

Cr√©ez un fichier .env √† la racine.

Ajoutez votre cl√© API Google :

GOOGLE_API_KEY="VOTRE_CL√â_API_GOOGLE"
Lancez l'application Streamlit :

Bash

streamlit run app.py
üß† D√©fis et Apprentissages
Le d√©fi principal dans un projet RAG est d'assurer la pertinence et la pr√©cision des r√©ponses tout en minimisant les hallucinations. J'ai beaucoup appris sur :

Le "Chunking" Strat√©gique : L'importance de bien d√©couper le texte pour pr√©server le contexte s√©mantique.

L'Optimisation des Prompts : La r√©daction de prompts qui forcent le LLM √† se baser uniquement sur le contexte fourni par les documents, en lui demandant de r√©pondre "Je ne sais pas" si l'information n'est pas pr√©sente.

La Gestion de la M√©moire Conversationnelle : Permettre au chatbot de se souvenir des questions pr√©c√©dentes pour des conversations plus fluides.
